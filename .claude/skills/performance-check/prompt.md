# Lighthouse & Accessibility Audit

Runs a full audit of the eclipse-con SPA: **Lighthouse** (Performance Â· Accessibility Â· Best-Practices Â· SEO) plus **axe-core WCAG 2.1 AA** runtime scan on all pages.

Scripts are in `.claude/skills/performance-check/scripts/` and output compact JSON â€” Claude parses and summarises them; raw JSON never enters the context.

---

## When to invoke

Triggered by: `/lighthouse`, "run a11y audit", "check performance", "WCAG scan", "accessibility check", "lighthouse audit".

---

## Steps

### 1 â€” Determine target

**Ask the user** which version to audit:

> "Which version do you want to audit?"
>
> - **Dev server** â€” starts `pnpm dev` (or reuses it if already running); runs Lighthouse + axe-core over HTTP.
> - **Static build** â€” uses the `dist-static/` single-file build; runs axe-core only (Lighthouse requires HTTP).

Use `ask_user` with choices `["Dev server (Lighthouse + axe-core)", "Static build (axe-core only)"]`.

---

#### If the user chooses **Dev server**

Check whether `pnpm dev` is already serving on port 5173:

```bash
curl -s -o /dev/null -w "%{http_code}" http://localhost:5173 2>/dev/null || echo "offline"
```

- **If 200** â†’ server is already up, proceed.
- **If offline** â†’ start the dev server as a background process and wait up to 30 s for it to become ready:

  ```bash
  pnpm dev &
  DEV_PID=$!
  for i in $(seq 1 30); do
    STATUS=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:5173 2>/dev/null)
    [ "$STATUS" = "200" ] && break
    sleep 1
  done
  echo "server_status:$STATUS"
  ```

  If it never responds with 200 after 30 s, report the error and stop.

Set `TARGET_URL=http://localhost:5173`.

Ask the user if they want `desktop` (default) or `mobile` form factor for Lighthouse.

---

#### If the user chooses **Static build**

Check whether the build is **fresh**: `dist-static/index.html` must exist **and** be newer than the most recently modified file under `src/` (any file: `.ts`, `.tsx`, `.css`, `.json`, etc.).

On Unix/macOS:

```bash
STATIC="dist-static/index.html"
if [ ! -f "$STATIC" ]; then
  echo "STALE: missing"
else
  NEWEST_SRC=$(find src -type f \( -name "*.ts" -o -name "*.tsx" -o -name "*.css" -o -name "*.json" \) -newer "$STATIC" | head -1)
  if [ -n "$NEWEST_SRC" ]; then echo "STALE: $NEWEST_SRC"; else echo "FRESH"; fi
fi
```

On Windows (PowerShell):

```powershell
$static = "dist-static\index.html"
if (-not (Test-Path $static)) { "STALE: missing" }
else {
  $buildTime = (Get-Item $static).LastWriteTime
  $newer = Get-ChildItem src -Recurse -Include *.ts,*.tsx,*.css,*.json |
           Where-Object { $_.LastWriteTime -gt $buildTime } | Select-Object -First 1
  if ($newer) { "STALE: $($newer.FullName)" } else { "FRESH" }
}
```

- **If FRESH** â†’ proceed with the existing build.
- **If STALE** â†’ inform the user which file triggered the rebuild, then run:

  ```bash
  pnpm build:static
  ```

  Wait for it to complete (allow up to 120 s). If it fails, report the error and stop.

Set `TARGET_URL=file:///$(pwd)/dist-static/index.html` (on Windows use the full absolute path with forward slashes: `file:///Z:/Github/eclipse-con/dist-static/index.html`).

> âš ï¸ Lighthouse is **skipped** for static builds â€” note this clearly in the report.

### 2 â€” Run scans (parallel)

Create the temp output directory (gitignored), then launch both scripts simultaneously:

```bash
mkdir -p .audit
```

> **Resuming after a partial run:** if `.audit/axe-checkpoint.json` exists, `axe-scan.mjs` will automatically skip already-completed routes and continue from where it left off. If `.audit/lh-result.json` already contains a valid result, `lh-scan.mjs` will output it immediately without re-running Lighthouse. Pass `--force` to `lh-scan.mjs` to discard the cache and run fresh.

**For HTTP targets â€” both scans in parallel:**

```bash
node .claude/skills/performance-check/scripts/axe-scan.mjs "$TARGET_URL" --routes root,/registration-tutorial \
  > .audit/axe-result.json 2>.audit/axe-err.txt &
AXE_PID=$!

node .claude/skills/performance-check/scripts/lh-scan.mjs "$TARGET_URL" "desktop" \
  > .audit/lh-result.json 2>.audit/lh-err.txt &
LH_PID=$!

wait $AXE_PID; AXE_EXIT=$?
wait $LH_PID;  LH_EXIT=$?
echo "axe:$AXE_EXIT lh:$LH_EXIT"
```

**For file:// targets â€” axe-core only:**

```bash
node .claude/skills/performance-check/scripts/axe-scan.mjs "$TARGET_URL" --routes root,/registration-tutorial \
  > .audit/axe-result.json 2>.audit/axe-err.txt
echo "axe:$?"
```

If any exit code is non-zero, read the matching `/tmp/*-err.txt` file and report the error to the user before continuing.

### 3 â€” Parse results (minimal context)

Read only what you need:

```bash
# Lighthouse scores + top issues
node -e "
const d = JSON.parse(require('fs').readFileSync('.audit/lh-result.json','utf8'));
const out = { scores: d.scores, topIssues: d.topIssues.slice(0,12), opportunities: d.opportunities };
console.log(JSON.stringify(out));
" 2>/dev/null || echo "LH_SKIPPED"
```

```bash
# axe summary + violations
node -e "
const d = JSON.parse(require('fs').readFileSync('.audit/axe-result.json','utf8'));
const out = { summary: d.summary, totalViolations: d.totalViolations, scanned: d.scanned, violations: d.violations };
console.log(JSON.stringify(out));
"
```

### 4 â€” Render report

Output a structured markdown report. Keep it concise â€” show scores, call out critical/serious issues, and group fixes by category.

### 5 â€” Save report

After rendering the report in the conversation, write the exact same markdown content to `.audit/report.md` using the `create` or `edit` tool (overwrite if it already exists). Confirm to the user where the file was saved.

---

## Report format

```markdown
## Audit Report â€” eclipse-con

**Target:** `<url>` | **Date:** <date> | **Form factor:** desktop/mobile

---

### Lighthouse Scores

| Category       | Score | Status   |
| -------------- | ----- | -------- |
| Performance    | XX    | ðŸŸ¢/ðŸŸ¡/ðŸ”´ |
| Accessibility  | XX    | ...      |
| Best Practices | XX    | ...      |
| SEO            | XX    | ...      |

> ðŸŸ¢ â‰¥ 90 ðŸŸ¡ 50â€“89 ðŸ”´ < 50

---

### Top Lighthouse Issues

Group by category. For each issue: `id`, score, display value, one-line description.
Show opportunities (time savings in ms) in a separate sub-section.

---

### Axe-Core WCAG 2.1 AA

**Scanned:** `/`, `/registration-tutorial`
**Violations:** X critical Â· Y serious Â· Z moderate Â· W minor

For each violation (sorted critical â†’ minor):

- **`rule-id`** [impact] â€” description
  - Count: N nodes Â· Routes: /foo, /bar
  - Example selector: `button.cta > span`
  - Fix: one-sentence actionable advice
  - Docs: <helpUrl>

---

### Summary & Priorities

Numbered list of the 5 most impactful fixes across both scans.
```

Score status emoji thresholds: ðŸŸ¢ â‰¥ 90 Â· ðŸŸ¡ 50â€“89 Â· ðŸ”´ < 50.

---

## Rules

- Never dump raw JSON into the conversation â€” always parse and summarise.
- Lighthouse requires HTTP. If target is `file://`, skip Lighthouse and note it clearly.
- If the dev server is offline, do not attempt to start it automatically â€” ask the user.
- Consent is pre-set in axe-scan.mjs so the tracking popup doesn't block the scan.
- Both scans run in parallel for HTTP targets to keep total time under 90 seconds.

---

## Resuming after failure

Both scripts write progress to disk immediately so a crashed or interrupted run can resume.

### Checkpoint files

| File                         | Created by     | Meaning                                                                                                                                                   |
| ---------------------------- | -------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `.audit/axe-checkpoint.json` | `axe-scan.mjs` | Per-route progress. Updated after every route. Deleted once findings are written.                                                                         |
| `.audit/axe-findings.json`   | `axe-scan.mjs` | **Full findings document** â€” all violations with uncapped node selectors, route breakdown, summary. Written on successful completion.                     |
| `.audit/lh-findings.json`    | `lh-scan.mjs`  | **Full findings document** â€” all failing audits (no slice limit), all opportunities with raw `details`, passing audits. Written on successful completion. |
| `.audit/lh-status.json`      | `lh-scan.mjs`  | Written before Lighthouse starts (`status: "running"`); updated to `status: "done"` on completion.                                                        |
| `.audit/lh-result.json`      | shell redirect | Summarised Lighthouse output (top 20 issues, top 8 opportunities). If present and valid, `lh-scan.mjs` reuses it automatically.                           |
| `.audit/axe-result.json`     | shell redirect | Summarised axe output. If present it means axe completed successfully.                                                                                    |

> **Findings vs result files:** `*-findings.json` files contain full, uncapped data intended for downstream agents and skills. `*-result.json` files are the summarised versions used by Claude to generate the report (kept small to avoid flooding the context window).

### How to resume

**axe-scan crashed mid-way:**

```bash
# Just re-run the same command â€” the checkpoint is picked up automatically
node .claude/skills/performance-check/scripts/axe-scan.mjs "$TARGET_URL" --routes root,/registration-tutorial \
  > .audit/axe-result.json 2>.audit/axe-err.txt
```

**Lighthouse crashed or result is stale:**

```bash
# Pass --force to discard the cached result and re-run Lighthouse
node .claude/skills/performance-check/scripts/lh-scan.mjs "$TARGET_URL" "desktop" --force \
  > .audit/lh-result.json 2>.audit/lh-err.txt
```

**Start completely fresh (wipe all intermediate state):**

```bash
rm -rf .audit && mkdir .audit
```
